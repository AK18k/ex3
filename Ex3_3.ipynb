{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AK18k/ex3/blob/main/Ex3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AK18k/ex3\n",
        "\n",
        "import os\n",
        "\n",
        "#from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = '/content/drive/MyDrive/Ex3/data'\n",
        "PATH = '/content/drive/MyDrive/Ex3'\n",
        "os.chdir('/content/drive/MyDrive/Ex3')"
      ],
      "metadata": {
        "id": "_gmAF3KS3EDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.modules.activation import Softplus\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# Define hyperparameters\n",
        "input_size = 28 * 28  # Size of the input images (28x28 pixels)\n",
        "latent_size = 50  # Length of the latent vector\n",
        "VAE_batch_size = 64\n",
        "SVM_batch_size = 64\n",
        "VAE_epochs = 10\n",
        "SVM_epochs = 10\n",
        "learning_rate = 1e-3\n",
        "num_hidden_units = 600\n",
        "num_of_labeled_samples = 100\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "g3oK_4RagXtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FashionMNIST dataset\n",
        "transform = transforms.ToTensor()\n",
        "train_dataset = datasets.FashionMNIST(root=DATA_PATH, train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.FashionMNIST(root=DATA_PATH, train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "w0CKdNquiISo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "# Split a dataset to labled and unlabled datasets\n",
        "# Inputs:\n",
        "#   - the dataset\n",
        "#   - number of labled samples required from the dataset\n",
        "# Output:\n",
        "#   - labled and unlabled datasets (not dataloaders)\n",
        "##############################################################\n",
        "\n",
        "# Define custom dataset for labeled and unlabeled data\n",
        "class SplitDataset(Dataset):\n",
        "    def __init__(self, dataset, labeled_indices):\n",
        "        self.dataset = dataset\n",
        "        self.labeled_indices = labeled_indices\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.dataset[self.labeled_indices[index]]\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labeled_indices)\n",
        "\n",
        "\n",
        "def split_to_labled(train_dataset, num_of_labeled_samples)\n",
        "  # Determine the number of labeled samples per class\n",
        "  num_classes = len(train_dataset.classes)\n",
        "  labeled_samples_per_class = num_of_labeled_samples // num_classes  # N is the desired number of labeled samples\n",
        "\n",
        "  # Split the dataset into labeled and unlabeled data\n",
        "  labeled_indices = []\n",
        "  unlabeled_indices = []\n",
        "  class_counts = [0] * num_classes\n",
        "\n",
        "  for i, (image, label) in enumerate(train_dataset):\n",
        "      if class_counts[label] < labeled_samples_per_class:\n",
        "          labeled_indices.append(i)\n",
        "          class_counts[label] += 1\n",
        "      else:\n",
        "          unlabeled_indices.append(i)\n",
        "\n",
        "  # Create labeled and unlabeled datasets\n",
        "  labeled_dataset = SplitDataset(train_dataset, labeled_indices)\n",
        "  unlabeled_dataset = torch.utils.data.Subset(train_dataset, unlabeled_indices)\n",
        "\n",
        "  # Print the number of labeled and unlabeled samples\n",
        "  print('Dataset split:')\n",
        "  print('--------------')\n",
        "  print(f\"Number of labeled samples: {len(labeled_dataset)}\")\n",
        "  print(f\"Number of unlabeled samples: {len(unlabeled_dataset)}\")\n",
        "\n",
        "  return labeled_dataset, unlabeled_dataset\n",
        "  '''\n",
        "  # Example usage: Creating data loaders\n",
        "  labeled_batch_size = 64\n",
        "  unlabeled_batch_size = 128\n",
        "\n",
        "  labeled_loader = DataLoader(labeled_dataset, batch_size=labeled_batch_size, shuffle=True)\n",
        "  unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=unlabeled_batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "  '''\n"
      ],
      "metadata": {
        "id": "45FlveOimQHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################################\n",
        "# Create and train the VAE model\n",
        "# Input:\n",
        "#   - data_loader - a dataloader with images and labels\n",
        "# Output:\n",
        "#   - the VAE model\n",
        "#####################################################################\n",
        "\n",
        "\n",
        "# Define the VAE architecture\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_size, latent_size):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_size, num_hidden_units),\n",
        "            nn.Softplus(),\n",
        "            nn.Linear(num_hidden_units, latent_size * 2)  # Output mu and logvar for each latent dimension\n",
        "        )\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_size, num_hidden_units),\n",
        "            nn.Softplus(),\n",
        "            nn.Linear(num_hidden_units, input_size),\n",
        "            nn.Sigmoid()  # Output values between 0 and 1\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        encoded = self.encoder(x)\n",
        "        mu, logvar = torch.chunk(encoded, 2, dim=1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        # Decoder\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed, mu, logvar\n",
        "\n",
        "\n",
        "def train_VAE(data_loader):\n",
        "  # Create VAE model\n",
        "  VAE_model = VAE(input_size, latent_size).to(device)\n",
        "\n",
        "  # Define loss function\n",
        "  criterion = nn.BCELoss(reduction='sum')  # Binary cross-entropy loss\n",
        "\n",
        "  # Define optimizer\n",
        "  optimizer = optim.Adam(VAE_model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(VAE_epochs):\n",
        "      for i, (images, _) in enumerate(data_loader):\n",
        "          # Flatten input images\n",
        "          images = images.view(images.size(0), -1).to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          reconstructed, mu, logvar = VAE_model(images)\n",
        "\n",
        "          # Compute reconstruction loss and KL divergence\n",
        "          reconstruction_loss = criterion(reconstructed, images)\n",
        "          kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "          # Total loss\n",
        "          loss = reconstruction_loss + kl_divergence\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          if (i+1) % 100 == 0:\n",
        "              print(f\"VAE train Epoch [{epoch+1}/{VAE_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "  return VAE_model\n",
        "\n"
      ],
      "metadata": {
        "id": "aokcicqztgDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################\n",
        "# Passes a dataset of images through a pretrained VAE model\n",
        "# Inputs:\n",
        "#   - VAE_model\n",
        "#   - data - the dataset (not a dataloader)\n",
        "# Output:\n",
        "#   - output_vectors - latent vectors\n",
        "###############################################################\n",
        "\n",
        "def images_to_latent(VAE_model, data)\n",
        "  data_loader = DataLoader(data, batch_size=VAE_batch_size, shuffle=False)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "  VAE_model.eval()\n",
        "\n",
        "  # Create an empty list to store the output vectors\n",
        "  output_vectors = []\n",
        "\n",
        "  # Pass the dataset through the VAE model\n",
        "  with torch.no_grad():\n",
        "      for images, _ in data_loader:\n",
        "          images = images.to(device)\n",
        "          # Obtain the output vectors from the VAE model\n",
        "          _, _, z = VAE_model(images)\n",
        "          output_vectors.append(z)\n",
        "\n",
        "  # Concatenate the output vectors into a single tensor\n",
        "  output_vectors = torch.cat(output_vectors, dim=0)\n",
        "\n",
        "  return output_vectors"
      ],
      "metadata": {
        "id": "tp_TWV9lrjQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################\n",
        "# Create, train and test SVM model\n",
        "# train_SVM: trains the SVM model.\n",
        "#           if TSVM is required - input a split dataset using split_to_labled(train_dataset, num_of_labeled_samples)\n",
        "# Input:\n",
        "#  - train_dataset (not dataloader)\n",
        "# Output:\n",
        "#  - SVM_model\n",
        "#\n",
        "# eval_SVM: evaluates on test dataset\n",
        "# - Input: SVM_model, test_dataset (not dataloader)\n",
        "# - Output: accuracy\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the SVM model\n",
        "class SVM(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SVM, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, 10)  # 10 classes for FashionMNIST\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "def train_SVM(train_dataset):\n",
        "\n",
        "  # Prepare dataloader\n",
        "  Y_train = train_dataset.targets\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=SVM_batch_size, shuffle=True)\n",
        "\n",
        "  # Create the SVM model\n",
        "  SVM_model = SVM(latent_size).to(device)\n",
        "  SVM_model.train()\n",
        "\n",
        "  # Define the loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Define the optimizer\n",
        "  optimizer = optim.SGD(SVM_model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(SVM_epochs):\n",
        "      for i, (images, _) in enumerate(train_loader):\n",
        "          # Flatten input images\n",
        "          images = images.view(images.size(0), -1).to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = SVM_model(images)\n",
        "          loss = criterion(outputs, Y_train[SVM_batch_size*i:SVM_batch_size*(i+1)].to(device))\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print training progress\n",
        "          if (i+1) % 100 == 0:\n",
        "              print(f\"SVM Train Epoch [{epoch+1}/{SVM_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "  return SVM_model\n",
        "\n",
        "def eval_SVM(SVM_model, test_dataset):\n",
        "\n",
        "  Y_test = test_dataset.targets\n",
        "  test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=SVM_batch_size, shuffle=False)\n",
        "\n",
        "  SVM_model.eval()\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.view(images.size(0), -1).to(device)\n",
        "          outputs = SVM_model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted.cpu() == labels).sum().item()\n",
        "\n",
        "      accuracy = correct / total\n",
        "      print(f\"SVM Test Accuracy: {accuracy:.4f}\"\n",
        "  return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "UuRHobL3dtHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}